{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":572434,"sourceType":"datasetVersion","datasetId":276801}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/ZahYou/my_other_project/blob/main/Nasas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"# Exploring\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, MaxPooling2D\nfrom keras.callbacks import LearningRateScheduler\n\n# Metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, roc_auc_score, roc_curve, classification_report,auc\nfrom scipy.stats import randint\n\n# Model\nfrom sklearn.ensemble import VotingRegressor, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.regularizers import l2\npd.options.display.max_columns = 500\npd.options.display.max_rows = 100\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"id":"54772acc","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:37.472060Z","iopub.execute_input":"2025-07-08T20:02:37.472478Z","iopub.status.idle":"2025-07-08T20:02:58.118697Z","shell.execute_reply.started":"2025-07-08T20:02:37.472448Z","shell.execute_reply":"2025-07-08T20:02:58.117564Z"}},"outputs":[{"name":"stderr","text":"2025-07-08 20:02:40.625087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752004960.867749      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752004960.934763      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/nasa-cmaps/CMaps/RUL_FD002.txt\n/kaggle/input/nasa-cmaps/CMaps/test_FD003.txt\n/kaggle/input/nasa-cmaps/CMaps/Damage Propagation Modeling.pdf\n/kaggle/input/nasa-cmaps/CMaps/readme.txt\n/kaggle/input/nasa-cmaps/CMaps/train_FD003.txt\n/kaggle/input/nasa-cmaps/CMaps/test_FD004.txt\n/kaggle/input/nasa-cmaps/CMaps/train_FD004.txt\n/kaggle/input/nasa-cmaps/CMaps/x.txt\n/kaggle/input/nasa-cmaps/CMaps/test_FD002.txt\n/kaggle/input/nasa-cmaps/CMaps/train_FD001.txt\n/kaggle/input/nasa-cmaps/CMaps/train_FD002.txt\n/kaggle/input/nasa-cmaps/CMaps/RUL_FD001.txt\n/kaggle/input/nasa-cmaps/CMaps/RUL_FD004.txt\n/kaggle/input/nasa-cmaps/CMaps/RUL_FD003.txt\n/kaggle/input/nasa-cmaps/CMaps/test_FD001.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/RUL_FD002.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/test_FD003.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/Damage Propagation Modeling.pdf\n/kaggle/input/nasa-cmaps/cmaps/CMaps/readme.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/train_FD003.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/test_FD004.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/train_FD004.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/x.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/test_FD002.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/train_FD001.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/train_FD002.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/RUL_FD001.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/RUL_FD004.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/RUL_FD003.txt\n/kaggle/input/nasa-cmaps/cmaps/CMaps/test_FD001.txt\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Goal:\n\nPredict the Remaining Useful Life (RUL) of turbofan engines using time-series sensor data from the CMAPSS dataset. The aim is to\n\nenable predictive maintenance—anticipating failures before they occur to optimize maintenance schedules and minimize downtime\n\n1. Introduction & Problem Statement\n2. Literature Review (highlighting state-of-the-art and gaps)\n3. Dataset Exploration & Preprocessing\n4. Feature Engineering & Selection\n5. Model Design (with justifications)\n6. Training & Evaluation\n7. Interpretability & Uncertainty Quantification\n8. Results & Discussion\n9. Conclusions & Future Work","metadata":{"id":"3132bc36"}},{"cell_type":"code","source":"# Define Columns name for indexing\nindex_name = [\"unit_nr\", \"time_in_cycles\"]\nsettings_name = [\"op_setting_1\",\"op_setting_2\", \"op_setting_3\"]\nsensors_name = [f\"sensor_{i}\" for i in range(22)]\n\ncols_name = index_name + settings_name + sensors_name\n#Load train,test and target with columns name\npath_train = \"/kaggle/input/nasa-cmaps/CMaps/train_FD001.txt\"\npath_test = \"/kaggle/input/nasa-cmaps/CMaps/test_FD001.txt\"\ntrain_df =  pd.read_csv(path_train,sep = \" \",header=None)\ntest_df = pd.read_csv(path_test,sep = \" \",header=None)\n\ncolumns = ['engine_number', 'time_in_cycles'] + [f'op_setting_{i}' for i in range(1, 4)] + [f'sensor_{i}' for i in range(1, 24)]\ntrain_df.columns = columns\ntest_df.columns = columns\n\ntest_df.columns = columns\n\ntest_df = test_df.iloc[0:].reset_index(drop=True)\n\ntest_df = test_df.drop(index=0).reset_index(drop=True)\ntrain_df.columns = columns\n\ntrain_df = train_df.iloc[0:].reset_index(drop=True)\n\ntrain_df = train_df.drop(index=0).reset_index(drop=True)\n\n# drop nan columns\ntrain_df = train_df.iloc[:, :-2]\ntest_df = test_df.iloc[:, :-2]\n\ntrain_df.head()","metadata":{"id":"7af9082e","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:58.128289Z","iopub.execute_input":"2025-07-08T20:02:58.129061Z","iopub.status.idle":"2025-07-08T20:02:58.471302Z","shell.execute_reply.started":"2025-07-08T20:02:58.129019Z","shell.execute_reply":"2025-07-08T20:02:58.470358Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   engine_number  time_in_cycles  op_setting_1  op_setting_2  op_setting_3  \\\n0              1               2        0.0019       -0.0003         100.0   \n1              1               3       -0.0043        0.0003         100.0   \n2              1               4        0.0007        0.0000         100.0   \n3              1               5       -0.0019       -0.0002         100.0   \n4              1               6       -0.0043       -0.0001         100.0   \n\n   sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  sensor_7  \\\n0    518.67    642.15   1591.82   1403.14     14.62     21.61    553.75   \n1    518.67    642.35   1587.99   1404.20     14.62     21.61    554.26   \n2    518.67    642.35   1582.79   1401.87     14.62     21.61    554.45   \n3    518.67    642.37   1582.85   1406.22     14.62     21.61    554.00   \n4    518.67    642.10   1584.47   1398.37     14.62     21.61    554.67   \n\n   sensor_8  sensor_9  sensor_10  sensor_11  sensor_12  sensor_13  sensor_14  \\\n0   2388.04   9044.07        1.3      47.49     522.28    2388.07    8131.49   \n1   2388.08   9052.94        1.3      47.27     522.42    2388.03    8133.23   \n2   2388.11   9049.48        1.3      47.13     522.86    2388.08    8133.83   \n3   2388.06   9055.15        1.3      47.28     522.19    2388.04    8133.80   \n4   2388.02   9049.68        1.3      47.16     521.68    2388.03    8132.85   \n\n   sensor_15  sensor_16  sensor_17  sensor_18  sensor_19  sensor_20  sensor_21  \n0     8.4318       0.03        392       2388      100.0      39.00    23.4236  \n1     8.4178       0.03        390       2388      100.0      38.95    23.3442  \n2     8.3682       0.03        392       2388      100.0      38.88    23.3739  \n3     8.4294       0.03        393       2388      100.0      38.90    23.4044  \n4     8.4108       0.03        391       2388      100.0      38.98    23.3669  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>engine_number</th>\n      <th>time_in_cycles</th>\n      <th>op_setting_1</th>\n      <th>op_setting_2</th>\n      <th>op_setting_3</th>\n      <th>sensor_1</th>\n      <th>sensor_2</th>\n      <th>sensor_3</th>\n      <th>sensor_4</th>\n      <th>sensor_5</th>\n      <th>sensor_6</th>\n      <th>sensor_7</th>\n      <th>sensor_8</th>\n      <th>sensor_9</th>\n      <th>sensor_10</th>\n      <th>sensor_11</th>\n      <th>sensor_12</th>\n      <th>sensor_13</th>\n      <th>sensor_14</th>\n      <th>sensor_15</th>\n      <th>sensor_16</th>\n      <th>sensor_17</th>\n      <th>sensor_18</th>\n      <th>sensor_19</th>\n      <th>sensor_20</th>\n      <th>sensor_21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0019</td>\n      <td>-0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>553.75</td>\n      <td>2388.04</td>\n      <td>9044.07</td>\n      <td>1.3</td>\n      <td>47.49</td>\n      <td>522.28</td>\n      <td>2388.07</td>\n      <td>8131.49</td>\n      <td>8.4318</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.0043</td>\n      <td>0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.26</td>\n      <td>2388.08</td>\n      <td>9052.94</td>\n      <td>1.3</td>\n      <td>47.27</td>\n      <td>522.42</td>\n      <td>2388.03</td>\n      <td>8133.23</td>\n      <td>8.4178</td>\n      <td>0.03</td>\n      <td>390</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0007</td>\n      <td>0.0000</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.45</td>\n      <td>2388.11</td>\n      <td>9049.48</td>\n      <td>1.3</td>\n      <td>47.13</td>\n      <td>522.86</td>\n      <td>2388.08</td>\n      <td>8133.83</td>\n      <td>8.3682</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.0019</td>\n      <td>-0.0002</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.00</td>\n      <td>2388.06</td>\n      <td>9055.15</td>\n      <td>1.3</td>\n      <td>47.28</td>\n      <td>522.19</td>\n      <td>2388.04</td>\n      <td>8133.80</td>\n      <td>8.4294</td>\n      <td>0.03</td>\n      <td>393</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>6</td>\n      <td>-0.0043</td>\n      <td>-0.0001</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.10</td>\n      <td>1584.47</td>\n      <td>1398.37</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.67</td>\n      <td>2388.02</td>\n      <td>9049.68</td>\n      <td>1.3</td>\n      <td>47.16</td>\n      <td>521.68</td>\n      <td>2388.03</td>\n      <td>8132.85</td>\n      <td>8.4108</td>\n      <td>0.03</td>\n      <td>391</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.98</td>\n      <td>23.3669</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"print(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)","metadata":{"id":"6f2a2408","outputId":"7935e267-108a-4ee5-a67f-323eb69c9eb0","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:58.473714Z","iopub.execute_input":"2025-07-08T20:02:58.474052Z","iopub.status.idle":"2025-07-08T20:02:58.479245Z","shell.execute_reply.started":"2025-07-08T20:02:58.474026Z","shell.execute_reply":"2025-07-08T20:02:58.478237Z"}},"outputs":[{"name":"stdout","text":"Train shape: (20630, 26)\nTest shape: (13095, 26)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def search_constant(df):\n    return df.columns[df.nunique() == 1].to_list()","metadata":{"id":"0b7eb78c","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:58.480198Z","iopub.execute_input":"2025-07-08T20:02:58.480554Z","iopub.status.idle":"2025-07-08T20:02:58.497390Z","shell.execute_reply.started":"2025-07-08T20:02:58.480507Z","shell.execute_reply":"2025-07-08T20:02:58.496318Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#train_df = train_df.drop(columns=search_constant(train_df))\n#test_df = test_df.drop(columns=search_constant(test_df))\n","metadata":{"id":"f55a3eff","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:58.498490Z","iopub.execute_input":"2025-07-08T20:02:58.498861Z","iopub.status.idle":"2025-07-08T20:02:58.516391Z","shell.execute_reply.started":"2025-07-08T20:02:58.498830Z","shell.execute_reply":"2025-07-08T20:02:58.515274Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_df.head()","metadata":{"id":"dd8c00ca","outputId":"6a3a2972-9756-4fa6-c037-990ca6990dfd","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:58.518072Z","iopub.execute_input":"2025-07-08T20:02:58.518474Z","iopub.status.idle":"2025-07-08T20:02:58.553097Z","shell.execute_reply.started":"2025-07-08T20:02:58.518440Z","shell.execute_reply":"2025-07-08T20:02:58.552230Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   engine_number  time_in_cycles  op_setting_1  op_setting_2  op_setting_3  \\\n0              1               2        0.0019       -0.0003         100.0   \n1              1               3       -0.0043        0.0003         100.0   \n2              1               4        0.0007        0.0000         100.0   \n3              1               5       -0.0019       -0.0002         100.0   \n4              1               6       -0.0043       -0.0001         100.0   \n\n   sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  sensor_7  \\\n0    518.67    642.15   1591.82   1403.14     14.62     21.61    553.75   \n1    518.67    642.35   1587.99   1404.20     14.62     21.61    554.26   \n2    518.67    642.35   1582.79   1401.87     14.62     21.61    554.45   \n3    518.67    642.37   1582.85   1406.22     14.62     21.61    554.00   \n4    518.67    642.10   1584.47   1398.37     14.62     21.61    554.67   \n\n   sensor_8  sensor_9  sensor_10  sensor_11  sensor_12  sensor_13  sensor_14  \\\n0   2388.04   9044.07        1.3      47.49     522.28    2388.07    8131.49   \n1   2388.08   9052.94        1.3      47.27     522.42    2388.03    8133.23   \n2   2388.11   9049.48        1.3      47.13     522.86    2388.08    8133.83   \n3   2388.06   9055.15        1.3      47.28     522.19    2388.04    8133.80   \n4   2388.02   9049.68        1.3      47.16     521.68    2388.03    8132.85   \n\n   sensor_15  sensor_16  sensor_17  sensor_18  sensor_19  sensor_20  sensor_21  \n0     8.4318       0.03        392       2388      100.0      39.00    23.4236  \n1     8.4178       0.03        390       2388      100.0      38.95    23.3442  \n2     8.3682       0.03        392       2388      100.0      38.88    23.3739  \n3     8.4294       0.03        393       2388      100.0      38.90    23.4044  \n4     8.4108       0.03        391       2388      100.0      38.98    23.3669  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>engine_number</th>\n      <th>time_in_cycles</th>\n      <th>op_setting_1</th>\n      <th>op_setting_2</th>\n      <th>op_setting_3</th>\n      <th>sensor_1</th>\n      <th>sensor_2</th>\n      <th>sensor_3</th>\n      <th>sensor_4</th>\n      <th>sensor_5</th>\n      <th>sensor_6</th>\n      <th>sensor_7</th>\n      <th>sensor_8</th>\n      <th>sensor_9</th>\n      <th>sensor_10</th>\n      <th>sensor_11</th>\n      <th>sensor_12</th>\n      <th>sensor_13</th>\n      <th>sensor_14</th>\n      <th>sensor_15</th>\n      <th>sensor_16</th>\n      <th>sensor_17</th>\n      <th>sensor_18</th>\n      <th>sensor_19</th>\n      <th>sensor_20</th>\n      <th>sensor_21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0019</td>\n      <td>-0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>553.75</td>\n      <td>2388.04</td>\n      <td>9044.07</td>\n      <td>1.3</td>\n      <td>47.49</td>\n      <td>522.28</td>\n      <td>2388.07</td>\n      <td>8131.49</td>\n      <td>8.4318</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.0043</td>\n      <td>0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.26</td>\n      <td>2388.08</td>\n      <td>9052.94</td>\n      <td>1.3</td>\n      <td>47.27</td>\n      <td>522.42</td>\n      <td>2388.03</td>\n      <td>8133.23</td>\n      <td>8.4178</td>\n      <td>0.03</td>\n      <td>390</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0007</td>\n      <td>0.0000</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.45</td>\n      <td>2388.11</td>\n      <td>9049.48</td>\n      <td>1.3</td>\n      <td>47.13</td>\n      <td>522.86</td>\n      <td>2388.08</td>\n      <td>8133.83</td>\n      <td>8.3682</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.0019</td>\n      <td>-0.0002</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.00</td>\n      <td>2388.06</td>\n      <td>9055.15</td>\n      <td>1.3</td>\n      <td>47.28</td>\n      <td>522.19</td>\n      <td>2388.04</td>\n      <td>8133.80</td>\n      <td>8.4294</td>\n      <td>0.03</td>\n      <td>393</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>6</td>\n      <td>-0.0043</td>\n      <td>-0.0001</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.10</td>\n      <td>1584.47</td>\n      <td>1398.37</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.67</td>\n      <td>2388.02</td>\n      <td>9049.68</td>\n      <td>1.3</td>\n      <td>47.16</td>\n      <td>521.68</td>\n      <td>2388.03</td>\n      <td>8132.85</td>\n      <td>8.4108</td>\n      <td>0.03</td>\n      <td>391</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.98</td>\n      <td>23.3669</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### How to Generate RUL Labels\n\n#### For each engine (unit), RUL at each cycle is:  RUL = max_cycle_for_engine − current_cycle\n","metadata":{"id":"6609655f"}},{"cell_type":"code","source":"# Group by eingin and get the max cycle for each\ntrain_df['time_in_cycles'] = pd.to_numeric(train_df['time_in_cycles'], errors='coerce')\n\nrul = pd.DataFrame(train_df.groupby('engine_number')['time_in_cycles'].max()).reset_index()\nrul.columns = ['engine_number', 'max_time_in_cycles']\ntrain_df = train_df.merge(rul, on='engine_number')\n\ntrain_df['RUL'] = train_df['max_time_in_cycles'] - train_df['time_in_cycles']\ntrain_df.drop('max_time_in_cycles', axis=1, inplace=True)\n\ntrain_df['RUL'] = train_df['RUL'].apply(lambda x: min(x, 130))\n\n#time_window = 50\n#train_df['label'] = train_df['RUL'].apply(lambda x: 1 if x > time_window else 0)","metadata":{"id":"5bd952bb","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:58.554085Z","iopub.execute_input":"2025-07-08T20:02:58.554413Z","iopub.status.idle":"2025-07-08T20:02:58.601219Z","shell.execute_reply.started":"2025-07-08T20:02:58.554388Z","shell.execute_reply":"2025-07-08T20:02:58.600017Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_df.head()","metadata":{"id":"4f126823","outputId":"252ced5c-7b3c-48ac-985e-414c95c6a1d0","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:58.602398Z","iopub.execute_input":"2025-07-08T20:02:58.602769Z","iopub.status.idle":"2025-07-08T20:02:58.630663Z","shell.execute_reply.started":"2025-07-08T20:02:58.602738Z","shell.execute_reply":"2025-07-08T20:02:58.629657Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   engine_number  time_in_cycles  op_setting_1  op_setting_2  op_setting_3  \\\n0              1               2        0.0019       -0.0003         100.0   \n1              1               3       -0.0043        0.0003         100.0   \n2              1               4        0.0007        0.0000         100.0   \n3              1               5       -0.0019       -0.0002         100.0   \n4              1               6       -0.0043       -0.0001         100.0   \n\n   sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  sensor_7  \\\n0    518.67    642.15   1591.82   1403.14     14.62     21.61    553.75   \n1    518.67    642.35   1587.99   1404.20     14.62     21.61    554.26   \n2    518.67    642.35   1582.79   1401.87     14.62     21.61    554.45   \n3    518.67    642.37   1582.85   1406.22     14.62     21.61    554.00   \n4    518.67    642.10   1584.47   1398.37     14.62     21.61    554.67   \n\n   sensor_8  sensor_9  sensor_10  sensor_11  sensor_12  sensor_13  sensor_14  \\\n0   2388.04   9044.07        1.3      47.49     522.28    2388.07    8131.49   \n1   2388.08   9052.94        1.3      47.27     522.42    2388.03    8133.23   \n2   2388.11   9049.48        1.3      47.13     522.86    2388.08    8133.83   \n3   2388.06   9055.15        1.3      47.28     522.19    2388.04    8133.80   \n4   2388.02   9049.68        1.3      47.16     521.68    2388.03    8132.85   \n\n   sensor_15  sensor_16  sensor_17  sensor_18  sensor_19  sensor_20  \\\n0     8.4318       0.03        392       2388      100.0      39.00   \n1     8.4178       0.03        390       2388      100.0      38.95   \n2     8.3682       0.03        392       2388      100.0      38.88   \n3     8.4294       0.03        393       2388      100.0      38.90   \n4     8.4108       0.03        391       2388      100.0      38.98   \n\n   sensor_21  RUL  \n0    23.4236  130  \n1    23.3442  130  \n2    23.3739  130  \n3    23.4044  130  \n4    23.3669  130  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>engine_number</th>\n      <th>time_in_cycles</th>\n      <th>op_setting_1</th>\n      <th>op_setting_2</th>\n      <th>op_setting_3</th>\n      <th>sensor_1</th>\n      <th>sensor_2</th>\n      <th>sensor_3</th>\n      <th>sensor_4</th>\n      <th>sensor_5</th>\n      <th>sensor_6</th>\n      <th>sensor_7</th>\n      <th>sensor_8</th>\n      <th>sensor_9</th>\n      <th>sensor_10</th>\n      <th>sensor_11</th>\n      <th>sensor_12</th>\n      <th>sensor_13</th>\n      <th>sensor_14</th>\n      <th>sensor_15</th>\n      <th>sensor_16</th>\n      <th>sensor_17</th>\n      <th>sensor_18</th>\n      <th>sensor_19</th>\n      <th>sensor_20</th>\n      <th>sensor_21</th>\n      <th>RUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0019</td>\n      <td>-0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>553.75</td>\n      <td>2388.04</td>\n      <td>9044.07</td>\n      <td>1.3</td>\n      <td>47.49</td>\n      <td>522.28</td>\n      <td>2388.07</td>\n      <td>8131.49</td>\n      <td>8.4318</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.0043</td>\n      <td>0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.26</td>\n      <td>2388.08</td>\n      <td>9052.94</td>\n      <td>1.3</td>\n      <td>47.27</td>\n      <td>522.42</td>\n      <td>2388.03</td>\n      <td>8133.23</td>\n      <td>8.4178</td>\n      <td>0.03</td>\n      <td>390</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0007</td>\n      <td>0.0000</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.45</td>\n      <td>2388.11</td>\n      <td>9049.48</td>\n      <td>1.3</td>\n      <td>47.13</td>\n      <td>522.86</td>\n      <td>2388.08</td>\n      <td>8133.83</td>\n      <td>8.3682</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.0019</td>\n      <td>-0.0002</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.00</td>\n      <td>2388.06</td>\n      <td>9055.15</td>\n      <td>1.3</td>\n      <td>47.28</td>\n      <td>522.19</td>\n      <td>2388.04</td>\n      <td>8133.80</td>\n      <td>8.4294</td>\n      <td>0.03</td>\n      <td>393</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>6</td>\n      <td>-0.0043</td>\n      <td>-0.0001</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.10</td>\n      <td>1584.47</td>\n      <td>1398.37</td>\n      <td>14.62</td>\n      <td>21.61</td>\n      <td>554.67</td>\n      <td>2388.02</td>\n      <td>9049.68</td>\n      <td>1.3</td>\n      <td>47.16</td>\n      <td>521.68</td>\n      <td>2388.03</td>\n      <td>8132.85</td>\n      <td>8.4108</td>\n      <td>0.03</td>\n      <td>391</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.98</td>\n      <td>23.3669</td>\n      <td>130</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"### [Raw Clean Data] (no NaNs)\n\n  ⮕ Keep all sensors, even low-variance ones\n\n  ⮕ Normalize (StandardScaler or MinMax)\n\n  ⮕ Generate time series sequences (sliding window)\n\n  ⮕ Train a baseline deep model (e.g., LSTM or Conv1D)\n\n  ⮕ Evaluate: MAE, RMSE, error curves vs. cycle\n\n  ⮕ THEN perform sensor ablation / feature pruning\n","metadata":{"id":"f8eff314"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Hash operating conditions\ntrain_df[\"op_hash\"] = train_df[[\"op_setting_1\", \"op_setting_2\"]].round(3).astype(str).agg(\"_\".join, axis=1)\ntest_df[\"op_hash\"] = test_df[[\"op_setting_1\", \"op_setting_2\"]].round(3).astype(str).agg(\"_\".join, axis=1)\n\n# Columns to normalize\nfeature_cols = [\n    'op_setting_1', 'op_setting_2','op_setting_3',\n    'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n    'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10',\n    'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15',\n    'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19',\n    'sensor_20', 'sensor_21'\n]\ntrain_df[feature_cols] = train_df[feature_cols].astype(\"float32\")\ntest_df[feature_cols]  = test_df[feature_cols].astype(\"float32\")\n\nscalers = {}\n\nfor op_id, group in train_df.groupby(\"op_hash\"):\n    scaler = StandardScaler()\n    scaler.fit(group[feature_cols])\n    scalers[op_id] = scaler\n    \n    # Apply scaler to train group\n    scaled = scaler.transform(group[feature_cols])\n    train_df.loc[group.index, feature_cols] = scaled\n\nglobal_scaler = StandardScaler()\nglobal_scaler.fit(train_df[feature_cols]) # Global fallback trained on full train_df\n\nfor op_id, group in test_df.groupby(\"op_hash\"):\n    if op_id in scalers:\n        scaler = scalers[op_id]\n        print(f\"✅ Normalizing with op_hash scaler for {op_id}\")\n    else:\n        scaler = global_scaler\n        print(f\"⚠️ Warning: op_hash {op_id} in test not seen in train. Using global scaler instead.\")\n    \n    scaled_features = scaler.transform(group[feature_cols])\n    test_df.loc[group.index, feature_cols] = scaled_features\n","metadata":{"id":"30e370a6","outputId":"dea9f930-61eb-4d43-9de4-368b24f342ee","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:43:55.100883Z","iopub.execute_input":"2025-07-08T20:43:55.101256Z","iopub.status.idle":"2025-07-08T20:44:21.280833Z","shell.execute_reply.started":"2025-07-08T20:43:55.101234Z","shell.execute_reply":"2025-07-08T20:44:21.279345Z"}},"outputs":[{"name":"stdout","text":"⚠️ Warning: op_hash -0.042_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.042_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.087_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.133_2.387 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.179_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.225_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.27_2.387 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.316_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.362_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.407_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.453_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.499_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.545_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.59_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.636_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.682_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.728_2.387 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.773_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.819_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.865_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.91_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -0.956_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.002_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.048_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.093_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.139_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.185_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.231_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.276_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.322_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.368_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.413_2.387 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.459_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.505_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.551_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.596_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.642_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.688_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.733_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.779_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.825_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.871_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.916_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -1.962_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.008_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.054_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.099_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.145_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.191_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.236_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.236_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.236_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.236_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.236_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.236_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.236_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.236_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.282_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.328_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.328_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.328_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.328_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.328_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.328_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.328_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.374_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.374_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.374_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.374_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.374_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.374_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.374_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.419_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.419_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.419_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.419_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.419_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.419_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.465_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.465_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.465_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.465_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.465_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.511_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.556_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.556_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.556_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.556_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.602_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.602_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.602_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.602_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.648_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.648_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.648_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.648_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.648_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.648_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.648_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.694_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.694_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.694_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.694_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.694_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.694_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.739_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.739_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.739_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.739_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.739_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.739_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.785_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.785_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.831_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.877_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.877_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.877_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.922_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.922_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.968_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.968_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -2.968_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.014_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.059_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.059_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.105_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.105_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.151_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.151_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.151_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.197_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.242_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.242_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.242_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.242_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.334_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.334_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.38_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.517_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.517_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.517_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.608_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash -3.745_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.004_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.05_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.095_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.141_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.187_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.233_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.278_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.324_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.37_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.416_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_-2.061 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.461_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.507_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.553_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.598_2.387 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.644_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.69_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.736_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.781_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.827_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.873_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.919_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 0.964_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.01_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.056_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.101_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.147_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.193_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.239_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.284_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.33_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.376_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.421_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.467_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.513_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.559_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.604_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.65_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.696_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.742_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.787_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.833_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.879_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.924_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 1.97_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.016_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.062_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.107_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.153_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.199_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.245_2.045 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.29_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.336_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.336_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.336_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.336_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.336_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.336_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.336_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.336_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.382_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.427_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.427_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.427_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.427_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.427_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.427_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.427_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.473_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.473_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.473_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.473_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.473_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.473_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.473_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.519_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.565_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.565_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.565_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.565_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.565_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.565_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.565_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.61_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.61_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.61_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.61_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.61_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.656_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.656_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.656_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.656_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.656_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.702_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.702_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.702_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.702_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.702_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.702_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.747_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.747_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.747_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.747_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.747_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.793_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.793_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.793_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.793_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.793_-1.377 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.793_0.676 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.793_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.793_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.839_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.839_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.839_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.885_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.93_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.93_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.93_0.334 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.93_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 2.93_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.022_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.022_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.113_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.113_1.018 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.159_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.205_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.296_-0.35 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.433_1.703 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.479_-0.692 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.479_-1.035 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.479_-1.719 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.479_1.361 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.525_-0.008 in test not seen in train. Using global scaler instead.\n⚠️ Warning: op_hash 3.57_-1.377 in test not seen in train. Using global scaler instead.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"Before:\n\nSome test samples were left raw (unscaled)\n\nThis broke the assumptions the model trained under (mean 0, std 1)\n\nNow:\n\nAll test samples — seen or unseen op_hash — are standardized\n\nYour model will behave more predictably on test engines\n\n","metadata":{}},{"cell_type":"code","source":"\"\"\"# Mean ~0, std ~1\nprint(train_df[feature_cols].mean())\nprint(train_df[feature_cols].std())\n\n# Confirm no leakage\nassert 'RUL' in train_df.columns\nassert train_df['RUL'].max() > 0\"\"\"","metadata":{"id":"4253748b","outputId":"698a4b1c-d3ec-4ef1-a61b-bf88e33ed268","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.060015Z","iopub.status.idle":"2025-07-08T20:02:59.060392Z","shell.execute_reply.started":"2025-07-08T20:02:59.060215Z","shell.execute_reply":"2025-07-08T20:02:59.060233Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Generate Time-Series Sequences (Sliding Window)\nNow reshape the data: for each engine, extract sliding windows of size N (e.g. 30 time steps), each labeled with the RUL at the final timestep.","metadata":{"id":"5f961cc7"}},{"cell_type":"code","source":"#sample_engine = train_df[train_df[\"engine_number\"] == 1]","metadata":{"id":"04aff022","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.062071Z","iopub.status.idle":"2025-07-08T20:02:59.062358Z","shell.execute_reply.started":"2025-07-08T20:02:59.062232Z","shell.execute_reply":"2025-07-08T20:02:59.062244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"fig, axs = plt.subplots(nrows=5, ncols=3, figsize=(15, 12))\nplt.subplots_adjust(hspace=0.5)\nfig.suptitle(\"Sensors over Cycle Time\", fontsize=18, y=0.95)\nfor sensor, ax in zip(sensors_name, axs.ravel()):\n    ax.plot(sample_engine['time_in_cycles'], sample_engine[sensor])\n    #ax.axvline(x = 200, color = \"red\")\n    ax.set_xlabel(f\"{sensor}\", color = \"green\")\n\n\nplt.show()\n# We see a common change on point cycle 200\"\"\"","metadata":{"id":"7a88aebf","outputId":"ee98be04-d4f9-4a08-d4df-21614127b333","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.064045Z","iopub.status.idle":"2025-07-08T20:02:59.065123Z","shell.execute_reply.started":"2025-07-08T20:02:59.064897Z","shell.execute_reply":"2025-07-08T20:02:59.064913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"fig, axs = plt.subplots(nrows=5, ncols=4, figsize=(16, 14))\nplt.subplots_adjust(hspace=0.5)\n#fig.suptitle(\"Sensors over Cycle Time\", fontsize=18, y=0.95)\nfor sensor, ax in zip(sensors_name, axs.ravel()):\n    ax.boxplot(train_df[sensor])\n    #ax.axvline(x = 200, color = \"red\")\n    ax.set_xlabel(f\"{sensor}\", color = \"green\")\n\n\nplt.show()\"\"\"","metadata":{"id":"ec6a98d3","outputId":"4c2f86d9-4355-4535-b701-90ca241fa788","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.066002Z","iopub.status.idle":"2025-07-08T20:02:59.066363Z","shell.execute_reply.started":"2025-07-08T20:02:59.066183Z","shell.execute_reply":"2025-07-08T20:02:59.066201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pd.DataFrame(train_df,columns=['sensor_{}'.format(i) for i in range(1,22)])","metadata":{"id":"d06a3467","outputId":"8d1331d8-620d-49c9-9eb3-ee266444426d","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.067526Z","iopub.status.idle":"2025-07-08T20:02:59.068105Z","shell.execute_reply.started":"2025-07-08T20:02:59.067879Z","shell.execute_reply":"2025-07-08T20:02:59.067901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if tf.test.gpu_device_name() != '/device:GPU:0':\n  print('WARNING: GPU device not found.')\nelse:\n  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))","metadata":{"id":"b68e3ce6","outputId":"dd1fc3e3-c832-4295-99e2-b0879247c18f","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:06:04.129656Z","iopub.execute_input":"2025-07-08T20:06:04.130092Z","iopub.status.idle":"2025-07-08T20:06:04.142443Z","shell.execute_reply.started":"2025-07-08T20:06:04.130061Z","shell.execute_reply":"2025-07-08T20:06:04.140499Z"}},"outputs":[{"name":"stdout","text":"WARNING: GPU device not found.\n","output_type":"stream"},{"name":"stderr","text":"2025-07-08 20:06:04.135362: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\nsns.set_context(\"notebook\", font_scale=1.)\nsns.set_style(\"whitegrid\")\n%config InlineBackend.figure_format = 'retina'","metadata":{"id":"6f96ce6a","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.073616Z","iopub.status.idle":"2025-07-08T20:02:59.074016Z","shell.execute_reply.started":"2025-07-08T20:02:59.073814Z","shell.execute_reply":"2025-07-08T20:02:59.073832Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TF Dataset Generator\ndef make_tf_sliding_window_dataset(data, window_size, batch_size):\n    \"\"\"\n    data: NumPy array of shape (timesteps, num_features + 1)\n    window_size: length of input sequence\n    batch_size: batch size for training\n    \"\"\"\n\n    total_features = data.shape[1] - 1 # Without RUL\n    ds = tf.data.Dataset.from_tensor_slices(data)\n\n    # Create sliding windows of size (window_size + 1)\n    ds = ds.window(window_size + 1, shift= 1, drop_remainder= True)\n    ds = ds.flat_map(lambda window: window.batch(window_size + 1))\n\n    # Split into (X,y)\n    ds = ds.map(lambda window: (window[:-1, :total_features], # X: first window_size rows, all features\n                                window[-1,-1]))  # y: last row's RUL\n    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return ds","metadata":{"id":"953f4e89","execution":{"iopub.status.busy":"2025-07-08T20:02:59.075025Z","iopub.status.idle":"2025-07-08T20:02:59.075398Z","shell.execute_reply.started":"2025-07-08T20:02:59.075218Z","shell.execute_reply":"2025-07-08T20:02:59.075234Z"}}},{"cell_type":"code","source":"\"\"\"for x_batch, y_batch in train_ds.take(1):\n    print(\"Input batch shape:\", x_batch.shape)  # Should be (batch_size, window_size, num_features)\n    print(\"Label batch shape:\", y_batch.shape)  # Should be (batch_size,)\n    print(\"First X sample:\\n\", x_batch[0].numpy())\n    print(\"First y sample:\", y_batch[0].numpy())\"\"\"","metadata":{"id":"GgHmyCpw6z-B","outputId":"bcabb3d1-6650-462e-9b6a-9dfd9689d4c2","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.076340Z","iopub.status.idle":"2025-07-08T20:02:59.076578Z","shell.execute_reply.started":"2025-07-08T20:02:59.076460Z","shell.execute_reply":"2025-07-08T20:02:59.076469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Flattened Dataset Generator\ndef make_tf_sliding_dataset(data, window_size, batch_size):\n  total_features = data.shape[1] -1 # -1 because last column is RUL\n\n  ds = tf.data.Dataset.from_tensor_slices(data)\n  ds = ds.window(window_size +1, shift = 1, drop_remainder= True)\n  ds = ds.flat_map(lambda window: window.batch(window_size + 1))\n\n  # Flatten input window\n  ds = ds.map(lambda window: (tf.reshape(window[:-1, : total_features], [-1]), #(window_size * num_features,)\n                              window[-1,-1])) # scaler RUL\n  return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"id":"fFv0OkcB8SgF","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.078044Z","iopub.status.idle":"2025-07-08T20:02:59.078335Z","shell.execute_reply.started":"2025-07-08T20:02:59.078214Z","shell.execute_reply":"2025-07-08T20:02:59.078226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"vBVPRlLltyyl","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:06:23.536300Z","iopub.execute_input":"2025-07-08T20:06:23.536708Z","iopub.status.idle":"2025-07-08T20:06:23.544717Z","shell.execute_reply.started":"2025-07-08T20:06:23.536677Z","shell.execute_reply":"2025-07-08T20:06:23.543348Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def make_flat_dataset_all_engines_normal(df, feature_cols, window_size=30, batch_size=64):\n    \"\"\"\n    Creates a flat tf.data.Dataset across all engines.\n\n    Args:\n        df: full DataFrame including all engines\n        feature_cols: list of feature column names (sensors + op_settings)\n        window_size: length of sliding window\n        batch_size: batch size for training\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    all_datasets = []\n\n    for engine_id in df['engine_number'].unique():\n        engine_df = df[df['engine_number'] == engine_id]\n        data = engine_df[feature_cols + ['RUL']].values\n\n        # Skip engines with short life\n        if data.shape[0] <= window_size:\n            continue\n\n        ds = tf.data.Dataset.from_tensor_slices(data)\n        ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n        ds = ds.flat_map(lambda window: window.batch(window_size + 1))\n\n        num_features = len(feature_cols)\n\n        # Flatten window and extract RUL\n        ds = ds.map(lambda w: (\n            tf.reshape(w[:-1, :num_features], [-1]),  # flatten window\n            w[-1, -1]  # RUL label\n        ))\n\n        all_datasets.append(ds)\n\n    # Combine all engines’ datasets\n    full_ds = all_datasets[0]\n    for ds in all_datasets[1:]:\n        full_ds = full_ds.concatenate(ds)\n\n    return full_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:02:59.082530Z","iopub.status.idle":"2025-07-08T20:02:59.082792Z","shell.execute_reply.started":"2025-07-08T20:02:59.082670Z","shell.execute_reply":"2025-07-08T20:02:59.082681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"CURRENT: Simple Dense Model (MAE ~13.4)\n    \nSTAGE 1: LSTM/Conv1D + Better RUL label + Optimized window size\n    \nSTAGE 2: Add deltas, regime normalization, engineered features\n    \nSTAGE 3: Hyperparam tuning + ensembles + smoothing\n\n\n\nGOAL: MAE ≤ 10, RMSE ≤ 13, R² ≥ 0.85\n","metadata":{}},{"cell_type":"code","source":"#make_sequence_dataset_all_engines() for LSTM.\ndef make_sequence_dataset_all_engines(df, feature_cols, window_size=30, batch_size=64):\n    all_datasets = []\n\n    for engine_id in df['engine_number'].unique():\n        engine_df = df[df['engine_number'] == engine_id]\n        data = engine_df[feature_cols + ['RUL']].values\n\n        if data.shape[0] <= window_size:\n            continue\n\n        ds = tf.data.Dataset.from_tensor_slices(data)\n        ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n        ds = ds.flat_map(lambda window: window.batch(window_size + 1))\n\n        num_features = len(feature_cols)\n\n        ds = ds.map(lambda window: (\n            window[:-1, :num_features],  # X: sequence, shape = (window_size, num_features)\n            window[-1, -1]               # y: scalar RUL at last timestep\n        ))\n\n        all_datasets.append(ds)\n\n    # Combine all engines\n    full_ds = all_datasets[0]\n    for ds in all_datasets[1:]:\n        full_ds = full_ds.concatenate(ds)\n\n    return full_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:07:54.163840Z","iopub.execute_input":"2025-07-08T20:07:54.164255Z","iopub.status.idle":"2025-07-08T20:07:54.172969Z","shell.execute_reply.started":"2025-07-08T20:07:54.164226Z","shell.execute_reply":"2025-07-08T20:07:54.171831Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# split the data by engine\nengine_ids = train_df[\"engine_number\"].unique()\n\n# Shuffle and split by engine ID\nnp.random.seed(42)\nnp.random.shuffle(engine_ids)\n\ntrain_ids = engine_ids[:int(0.7* len(engine_ids))] # 70% train\nval_ids = engine_ids[int(0.7 * len(engine_ids)): int(0.85 * len(engine_ids))] # 15% val\ntest_ids = engine_ids[int(0.85 * len(engine_ids)):] # 15% val\n# Filter DataFrames\ntrain_df_split = train_df[train_df[\"engine_number\"].isin(train_ids)]\nval_df_split = train_df[train_df[\"engine_number\"].isin(val_ids)]\ntest_df_split = train_df[train_df[\"engine_number\"].isin(test_ids)]\n# Build data\ntrain_ds = make_sequence_dataset_all_engines(train_df_split, feature_cols, window_size=30, batch_size=64)\nval_ds   = make_sequence_dataset_all_engines(val_df_split, feature_cols, window_size=30, batch_size=64)\ntest_ds  = make_sequence_dataset_all_engines(test_df_split, feature_cols, window_size=30, batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:45:08.394492Z","iopub.execute_input":"2025-07-08T20:45:08.394815Z","iopub.status.idle":"2025-07-08T20:45:12.456252Z","shell.execute_reply.started":"2025-07-08T20:45:08.394795Z","shell.execute_reply":"2025-07-08T20:45:12.454785Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"for x_batch, y_batch in train_ds.take(1):\n    print(\"Input shape:\", x_batch.shape)  # should be (batch_size, 30, num_features)\n    print(\"Label shape:\", y_batch.shape)  # should be (batch_size,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:45:17.239747Z","iopub.execute_input":"2025-07-08T20:45:17.240330Z","iopub.status.idle":"2025-07-08T20:45:17.647228Z","shell.execute_reply.started":"2025-07-08T20:45:17.240303Z","shell.execute_reply":"2025-07-08T20:45:17.645934Z"}},"outputs":[{"name":"stdout","text":"Input shape: (64, 30, 24)\nLabel shape: (64,)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\nwindow_size = 80\nnum_features = 24\n\nmodel = models.Sequential([\n    layers.Input(shape=(window_size, num_features)),  # (30, 23)\n    layers.LSTM(64, return_sequences=False),          # outputs: (batch_size, 64)\n    layers.Dense(32, activation='relu'),              # (batch_size, 32)\n    layers.Dense(1)                                   # (batch_size, 1) → RUL\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='mae',              \n    metrics=['mae', 'mse']   \n)\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=10\n)\n\nhistory.model.evaluate(test_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:08:28.742820Z","iopub.execute_input":"2025-07-08T20:08:28.743689Z","iopub.status.idle":"2025-07-08T20:09:23.899141Z","shell.execute_reply.started":"2025-07-08T20:08:28.743651Z","shell.execute_reply":"2025-07-08T20:09:23.898319Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n    191/Unknown \u001b[1m8s\u001b[0m 23ms/step - loss: 77.0334 - mae: 77.0334 - mse: 7768.0493","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 77.0089 - mae: 77.0089 - mse: 7764.0928 - val_loss: 62.7923 - val_mae: 62.7923 - val_mse: 5438.8979\nEpoch 2/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 55.6445 - mae: 55.6445 - mse: 4344.2314 - val_loss: 43.7604 - val_mae: 43.7604 - val_mse: 2485.4126\nEpoch 3/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 41.1884 - mae: 41.1884 - mse: 2185.4622 - val_loss: 39.1193 - val_mae: 39.1193 - val_mse: 1913.5948\nEpoch 4/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 38.3048 - mae: 38.3048 - mse: 1862.6024 - val_loss: 38.4403 - val_mae: 38.4403 - val_mse: 1884.3241\nEpoch 5/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 37.9462 - mae: 37.9462 - mse: 1861.6716 - val_loss: 38.3219 - val_mae: 38.3219 - val_mse: 1893.9741\nEpoch 6/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 37.8972 - mae: 37.8972 - mse: 1873.7799 - val_loss: 38.2936 - val_mae: 38.2936 - val_mse: 1899.2819\nEpoch 7/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 37.8874 - mae: 37.8874 - mse: 1878.7007 - val_loss: 38.2896 - val_mae: 38.2896 - val_mse: 1900.3873\nEpoch 8/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 37.8866 - mae: 37.8866 - mse: 1880.0135 - val_loss: 38.2875 - val_mae: 38.2875 - val_mse: 1900.9899\nEpoch 9/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 37.8862 - mae: 37.8862 - mse: 1880.7742 - val_loss: 38.2854 - val_mae: 38.2854 - val_mse: 1901.5897\nEpoch 10/10\n\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 37.8860 - mae: 37.8860 - mse: 1881.5198 - val_loss: 38.2844 - val_mae: 38.2844 - val_mse: 1901.8855\n\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 37.1166 - mae: 37.1166 - mse: 1825.5762\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[38.249969482421875, 38.249969482421875, 1903.152099609375]"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"\nresults = []\n\nwindow_sizes = [30, 50, 70, 80]\nbatch_size = 64\nnum_features = len(feature_cols)\n\nfor w in window_sizes:\n    print(f\"\\n Training model with window_size = {w}\")\n\n    # 1. Build datasets\n    train_ds = make_sequence_dataset_all_engines(train_df_split, feature_cols, window_size=w, batch_size=batch_size)\n    val_ds = make_sequence_dataset_all_engines(val_df_split, feature_cols, window_size=w, batch_size=batch_size)\n    test_ds = make_sequence_dataset_all_engines(test_df_split, feature_cols, window_size=w, batch_size=batch_size)\n\n    # 2. Define model\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(w, num_features)),\n        tf.keras.layers.LSTM(64),\n        tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\n\n    model.compile(optimizer='adam', loss='mae', metrics=['mae', 'mse'])\n\n    # 3. Train\n    model.fit(train_ds, validation_data=val_ds, epochs=10, verbose=0)\n\n    # 4. Evaluate on test\n    mae, mse = model.evaluate(test_ds, verbose=0)[1:]  # [loss, mae, mse] → skip loss\n    rmse = np.sqrt(mse)\n\n    print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n\n    # 5. Save results\n    results.append({\n        'window_size': w,\n        'model_type': 'LSTM',\n        'num_features': num_features,\n        'MAE': round(mae, 2),\n        'RMSE': round(rmse, 2),\n        'MSE': round(mse, 2)\n    })\n\n# 6. Convert to DataFrame\nresults_df = pd.DataFrame(results)\nprint(\"\\n Results Summary:\")\nprint(results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:45:32.129105Z","iopub.execute_input":"2025-07-08T20:45:32.129493Z","iopub.status.idle":"2025-07-08T20:50:10.296344Z","shell.execute_reply.started":"2025-07-08T20:45:32.129471Z","shell.execute_reply":"2025-07-08T20:50:10.295003Z"}},"outputs":[{"name":"stdout","text":"\n Training model with window_size = 30\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"MAE: 18.88, RMSE: 26.47\n\n Training model with window_size = 50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"MAE: 16.22, RMSE: 23.78\n\n Training model with window_size = 70\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"MAE: 15.46, RMSE: 22.20\n\n Training model with window_size = 80\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"MAE: 18.88, RMSE: 25.53\n\n Results Summary:\n   window_size model_type  num_features    MAE   RMSE     MSE\n0           30       LSTM            24  18.88  26.47  700.46\n1           50       LSTM            24  16.22  23.78  565.63\n2           70       LSTM            24  15.46  22.20  493.06\n3           80       LSTM            24  18.88  25.53  651.59\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"\nwindow_size = 70\nnum_features = 24\n\nmodel = models.Sequential([\n    layers.Input(shape=(window_size, num_features)),  # (30, 24)\n    layers.LSTM(64, return_sequences=False),          # outputs: (batch_size, 64)\n    layers.Dense(32, activation='relu'),              # (batch_size, 32)\n    layers.Dense(1)                                   # (batch_size, 1) → RUL\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='mae',              \n    metrics=['mae', 'mse']   \n)\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=10\n)\n\nhistory.model.evaluate(test_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:53:16.647463Z","iopub.execute_input":"2025-07-08T20:53:16.647769Z","iopub.status.idle":"2025-07-08T20:54:27.662231Z","shell.execute_reply.started":"2025-07-08T20:53:16.647747Z","shell.execute_reply":"2025-07-08T20:54:27.661273Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n    136/Unknown \u001b[1m9s\u001b[0m 42ms/step - loss: 59.6072 - mae: 59.6072 - mse: 5137.3804","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - loss: 59.5067 - mae: 59.5067 - mse: 5124.1890 - val_loss: 35.3698 - val_mae: 35.3698 - val_mse: 1874.2443\nEpoch 2/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 27.6603 - mae: 27.6603 - mse: 1274.0635 - val_loss: 20.8083 - val_mae: 20.8083 - val_mse: 642.0071\nEpoch 3/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 17.4628 - mae: 17.4628 - mse: 516.8900 - val_loss: 19.2759 - val_mae: 19.2759 - val_mse: 599.3884\nEpoch 4/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - loss: 15.8806 - mae: 15.8806 - mse: 436.7550 - val_loss: 21.1580 - val_mae: 21.1580 - val_mse: 725.3654\nEpoch 5/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - loss: 15.8536 - mae: 15.8536 - mse: 443.7166 - val_loss: 16.9407 - val_mae: 16.9407 - val_mse: 481.7675\nEpoch 6/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - loss: 14.1358 - mae: 14.1358 - mse: 358.0416 - val_loss: 16.7042 - val_mae: 16.7042 - val_mse: 480.2836\nEpoch 7/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 13.6430 - mae: 13.6430 - mse: 338.2506 - val_loss: 15.3664 - val_mae: 15.3664 - val_mse: 431.0267\nEpoch 8/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 13.1152 - mae: 13.1152 - mse: 319.8337 - val_loss: 14.9444 - val_mae: 14.9444 - val_mse: 373.3595\nEpoch 9/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - loss: 13.5072 - mae: 13.5072 - mse: 327.7977 - val_loss: 13.8851 - val_mae: 13.8851 - val_mse: 341.6788\nEpoch 10/10\n\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - loss: 12.5277 - mae: 12.5277 - mse: 295.0277 - val_loss: 14.1545 - val_mae: 14.1545 - val_mse: 360.0933\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 12.7318 - mae: 12.7318 - mse: 313.5963\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[12.601237297058105, 12.601237297058105, 305.5946044921875]"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# y_true and y_pred for test_ds\n# Plot prediction error distribution and residuals\n\n# Get true RUL values from the test_ds\ny_true = []\nfor _, labels in test_ds:\n    y_true.extend(labels.numpy())\ny_true = np.array(y_true)\n\n# Get predicted RUL values from the test_ds\ny_pred = model.predict(test_ds).flatten()\n\n# Calculate prediction errors\nerrors = y_pred - y_true\n\n# Visualize Prediction Error Distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(errors, bins=50, kde=True)\nplt.title('Distribution of Prediction Errors (Predicted RUL - True RUL)')\nplt.xlabel('Prediction Error')\nplt.ylabel('Frequency')\nplt.show()\n\n\ndef score_func(y_true,y_pred):\n    lst = [\n          round(mean_absolute_error(y_true,y_pred),2),\n          round(mean_squared_error(y_true,y_pred),2)**0.5,\n          round(r2_score(y_true,y_pred),2)]\n\n    print(f' mean absolute error {lst[0]}')\n    print(f' root mean squared error {lst[1]}')\n    print(f' R2 score {lst[2]}')\n\nscore_func(y_true, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T20:56:43.714547Z","iopub.execute_input":"2025-07-08T20:56:43.715409Z","iopub.status.idle":"2025-07-08T20:56:46.833553Z","shell.execute_reply.started":"2025-07-08T20:56:43.715381Z","shell.execute_reply":"2025-07-08T20:56:46.832557Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":" mean absolute error 12.6\n root mean squared error 17.48113268641366\n R2 score 0.82\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# asymetric loss func\n\ndef asymetric_loss(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    error = y_pred - y_true\n    factor = tf.where(error > 0, 2.0, 1.0) # Penalisation \n    return tf.reduce_mean(factor * tf.abs(error))\n    \nasymetric_loss(y_true, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T21:07:47.829729Z","iopub.execute_input":"2025-07-08T21:07:47.830146Z","iopub.status.idle":"2025-07-08T21:07:47.847064Z","shell.execute_reply.started":"2025-07-08T21:07:47.830117Z","shell.execute_reply":"2025-07-08T21:07:47.845662Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(), dtype=float32, numpy=21.74039077758789>"},"metadata":{}}],"execution_count":36}]}